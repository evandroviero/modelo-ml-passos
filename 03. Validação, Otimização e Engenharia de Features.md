# Roteiro de Estudos de ML – Módulo 3: Validação, Otimização e Engenharia e Seleção de Features

O próximo passo é garantir que eles não apenas funcionem, mas que sejam robustos, generalizáveis e performáticos. Este módulo aborda três pilares práticos que formam o núcleo do trabalho de um cientista de dados:

* **Validação**: Como podemos confiar que o desempenho do nosso modelo em dados de teste se manterá para dados futuros?
* **Otimização**: Como encontrar a melhor "sintonia fina" (hiperparâmetros) para um algoritmo?
* **Engenharia de Features**: Como podemos transformar e criar variáveis para que o modelo aprenda com mais eficiência?
* **Seleção de Features**: Como escolher o subconjunto de variáveis mais importante,

## Validação de Modelos
* **Objetivo**: Estimar de forma confiável o desempenho de um modelo em dados novos e não vistos, evitando as armadilhas do overfitting e underfitting.
    * **Overfitting (Sobreajuste)**: Ocorre quando o modelo "decora" os dados de treino, incluindo seus ruídos e particularidades. Ele performa perfeitamente no treino, mas falha drasticamente em generalizar para novos dados.
    * **Underfitting (Subajuste)**: Ocorre quando o modelo é simples demais e não consegue capturar os padrões e a complexidade existentes nos dados. Ele performa mal tanto no treino quanto em dados novos.
* **Características**: A validação é caracterizada pela separação sistemática dos dados em diferentes conjuntos, cada um com um propósito específico, para simular o comportamento do modelo em um ambiente de produção.
* **Avaliações**: A avaliação de uma estratégia de validação é feita pela estabilidade e confiabilidade da métrica de performance (ex: RMSE, F1-Score) obtida. Uma boa técnica de validação produz uma estimativa de erro que é um reflexo fiel do erro que o modelo terá em produção.

* Formas de Execução
    1. Holdout Simples (Divisão Treino-Teste):
        * **Execução**: Os dados são divididos em dois conjuntos: um para treino (geralmente 70-80%) e um para teste (20-30%). O modelo é treinado no primeiro e avaliado no segundo.
        * **Quando usar**: É a forma mais simples e rápida. Aconselhada para datasets muito grandes, onde uma única divisão já é representativa o suficiente.
        Cuidado: O resultado pode variar muito dependendo de como a divisão aleatória foi feita. Uma "sorte" ou "azar" na divisão pode levar a uma avaliação excessivamente otimista ou pessimista.
    2. Holdout com Conjunto de Validação (Divisão Treino-Validação-Teste):
        * **Execução**: Os dados são divididos em três conjuntos:
        * **Treino**: Usado para treinar o modelo.
        * **Validação**: Usado para otimizar os hiperparâmetros e selecionar o melhor modelo (ver seção 2).
        * **Teste**: Usado apenas uma vez no final do processo para obter a métrica de desempenho final e imparcial do modelo escolhido.
        * **Quando usar**: É o padrão da indústria para a maioria dos projetos, pois separa claramente a fase de otimização da fase de avaliação final, evitando "vazamento de dados" (data leakage) do conjunto de teste para o modelo.
    3. Validação Cruzada (K-Fold Cross-Validation):
        * **Execução**:
            * Os dados (sem o conjunto de teste, que deve ser guardado à parte) são divididos em 'K' partes iguais (ex: K=5 ou K=10).
            * O modelo é treinado 'K' vezes. A cada vez, ele usa K-1 partes para treino e a parte restante para teste.
            * A métrica de desempenho final é a média das métricas obtidas nas 'K' rodadas.
        * **Quando usar**: É a abordagem mais robusta e confiável, especialmente para datasets de tamanho pequeno a médio. Ela garante que todos os dados foram usados tanto para treinar quanto para validar o modelo, reduzindo a variância da estimativa de performance.
        * **Variação Importante**: Para classificação, usa-se a Validação Cruzada Estratificada (Stratified K-Fold), que garante que a proporção das classes seja a mesma em cada uma das 'K' divisões, essencial para dados desbalanceados.

### Otimização de Hiperparâmetros (Hyperparameter Tuning)
* **Objetivo**: Encontrar a combinação de hiperparâmetros de um modelo que maximize sua performance na métrica de avaliação escolhida. Hiperparâmetros são as "configurações" do algoritmo que não são aprendidas durante o treino (ex: o número de árvores em um Random Forest, o valor 'K' no KNN).
* **Características**: É um processo de busca em um "espaço" de possíveis combinações de hiperparâmetros. É um processo iterativo e computacionalmente intensivo.
* **Avaliações**: A avaliação é feita usando uma métrica de performance (ex: AUC, MAE) no conjunto de validação. A combinação de hiperparâmetros que gera o melhor resultado nesta métrica é a escolhida. O conjunto de teste nunca deve ser usado neste processo.

* Formas de Execução
    1. Grid Search (Busca em Grade):
        * **Execução**: Define-se uma "grade" de valores para cada hiperparâmetro a ser otimizado. O algoritmo então testa exaustivamente todas as combinações possíveis.
        * **Quando usar**: Quando o espaço de busca é pequeno (poucos hiperparâmetros e poucos valores para testar). É fácil de entender, mas seu custo computacional cresce exponencialmente.
    2. Random Search (Busca Aleatória):
        * **Execução**: Em vez de testar todas as combinações, ele sorteia um número fixo de combinações aleatórias dentro do espaço de busca definido.
        * **Quando usar**: É quase sempre mais eficiente que o Grid Search. Frequentemente, apenas alguns hiperparâmetros são realmente importantes, e a busca aleatória tem uma chance maior de encontrar bons valores para eles em menos tempo. É a abordagem mais recomendada na prática.
    3. Otimização Bayesiana:
        * **Execução**: É uma abordagem "inteligente". Ela constrói um modelo de probabilidade que mapeia os hiperparâmetros à métrica de performance. A cada iteração, ela usa esse modelo para decidir qual a próxima combinação de hiperparâmetros que tem a maior probabilidade de melhorar o resultado, aprendendo com as tentativas anteriores.
        * **Quando usar**: Quando o custo de avaliar uma única combinação é muito alto (ex: treinar um modelo de deep learning por horas). É muito mais eficiente em termos de número de iterações do que as buscas cegas (Grid/Random).

### Engenharia de Features
**Objetivo**: Usar o conhecimento de negócio e técnicas estatísticas para limpar, transformar e criar novas features (variáveis) a partir dos dados brutos. O objetivo é tornar os padrões nos dados mais fáceis de serem aprendidos pelos algoritmos.
**Características**: É um processo que mistura "arte" (criatividade, conhecimento do domínio) e "ciência" (técnicas de pré-processamento). Frequentemente, é a etapa que traz os maiores ganhos de performance para um modelo.
**Avaliações**: A avaliação é empírica: uma nova feature é criada, o modelo é retreinado e sua performance no conjunto de validação é reavaliada. Se a métrica melhorar, a feature é considerada útil. Técnicas como "feature importance" de modelos de árvore também ajudam a avaliar a relevância das features.

* Formas de Execução (Técnicas Comuns)
    1. Imputação de Dados Faltantes:
        * **Execução**: Preencher valores ausentes com a média, mediana (para números) ou moda (para categorias). Métodos mais avançados usam modelos como KNN para prever o valor faltante com base nos vizinhos.
    2. Tratamento de Outliers:
        * **Execução**: Identificar e tratar valores extremos que podem prejudicar o modelo. As abordagens incluem remover o outlier, aplicar um "teto" (capping) ou transformar a variável (ex: com logaritmo) para reduzir seu impacto.
    3. Encoding de Variáveis Categóricas:
        * **Execução**: Converter texto em números.
            * **One-Hot Encoding**: Cria uma nova coluna binária para cada categoria. Ideal para variáveis com poucas categorias.
            * **Label Encoding**: Atribui um número inteiro para cada categoria. Cuidado, pois pode criar uma ordem artificial que não existe.
            * **Target Encoding**: Substitui a categoria pela média da variável alvo para aquela categoria. Poderoso, mas requer cuidado para evitar overfitting.
    4. Binning / Discretização:
        * **Execução**: Transformar uma variável numérica contínua em uma variável categórica. Ex: transformar "idade" em faixas como "Criança", "Adolescente", "Adulto", "Idoso". Pode ajudar modelos lineares a capturar relações não-lineares.
    5. Transformações de Escala e Distribuição:
        * **Execução**:
            **Padronização (StandardScaler)**: Transforma os dados para terem média 0 e desvio padrão 1. Essencial para modelos sensíveis à escala (como SVM, Regressão Logística).
            **Normalização (MinMaxScaler)**: Coloca todos os valores no intervalo [0, 1].
            **Transformação Logarítmica**: Aplica log(x) para reduzir o efeito de "caudas longas" em distribuições de dados muito assimétricas.
    6. Criação de Novas Features:
        Execução: A parte mais criativa.
            * **Features Polinomiais/Interação**: Criar features que são combinações de outras (ex: largura * altura para criar area).
            * **Features de Data e Hora**: Extrair de uma data o dia da semana, mês, ano, se é feriado, etc.
            * **Features de Agregação**: Criar estatísticas a partir de outros dados (ex: para um cliente, calcular o gasto_medio_por_compra ou dias_desde_a_ultima_compra).

### Seleção de Features (Feature Selection)
* **Objetivo**: Reduzir o número de variáveis de entrada (features) de um modelo, mantendo apenas o subconjunto mais relevante para o problema. O objetivo é simplificar o modelo e melhorar sua performance.
* **Características**: A seleção de features é um processo de filtragem que busca combater a "maldição da dimensionalidade" (curse of dimensionality), onde um número excessivo de features pode prejudicar o modelo. Os principais benefícios são:
    * **Reduz o Overfitting**: Menos features significam menos chance de o modelo aprender com ruídos e correlações falsas.
    * **Melhora a Performance**: Remover features irrelevantes ou redundantes pode ajudar o modelo a focar nos sinais verdadeiros, melhorando sua precisão.
    * **Aumenta a Eficiência**: Menos features resultam em um tempo de treinamento e de previsão muito menor.
    * **Melhora a Interpretabilidade**: É muito mais fácil entender e explicar um modelo com 15 features do que um com 150.
* **Avaliações**: A avaliação de um subconjunto de features é feita de forma empírica: seleciona-se um conjunto de variáveis, treina-se o modelo e avalia-se sua performance no conjunto de validação. Se o desempenho for mantido ou melhorado com menos features, a seleção foi bem-sucedida.
* **Formas de Execução**: Existem três famílias principais de métodos de seleção de features:
    * **Métodos de Filtro (Filter Methods)**:
        * **Execução**: São aplicados antes do treinamento do modelo. Eles usam testes estatísticos para atribuir uma pontuação a cada feature, e as features são selecionadas ou descartadas com base nessa pontuação. Eles não dependem de um modelo de ML.
        **Técnicas Comuns**:
            * **Análise de Correlação**: Remove features que são altamente correlacionadas entre si (ex: correlação > 0.95), pois elas carregam informação redundante.
            * **Testes Estatísticos**: Usa-se testes como o Qui-quadrado (Chi-squared) para avaliar a relação entre duas variáveis categóricas (feature e alvo) ou ANOVA para avaliar a relação entre uma variável numérica e uma categórica (feature e alvo).
        * **Quando usar**: São muito rápidos e computacionalmente baratos. Ideais para uma primeira triagem ou "limpeza" das features.
    * **Métodos de Empacotamento (Wrapper Methods)**:
        * **Execução**: Utilizam um modelo de Machine Learning para avaliar a utilidade de diferentes subconjuntos de features. Eles "empacotam" o processo de seleção em torno do treinamento do modelo.
        * **Técnicas Comuns**:
            * **Eliminação Recursiva de Features (RFE - Recursive Feature Elimination)**: Treina um modelo, avalia a importância de cada feature, remove a menos importante e repete o processo até atingir o número desejado de features.
            * **Seleção Progressiva (Forward Selection)**: Começa sem nenhuma feature e vai adicionando, uma a uma, a feature que mais melhora o desempenho do modelo.
            * **Eliminação Regressiva (Backward Elimination)**: Começa com todas as features e vai removendo, uma a uma, a feature cuja remoção menos prejudica (ou mais melhora) o desempenho.
        * **Quando usar**: Quando o objetivo é encontrar o subconjunto de features de melhor performance possível. São muito mais poderosos que os métodos de filtro, mas computacionalmente muito mais caros.
    * **Métodos Embutidos (Embedded Methods)**:
        * **Execução**: A seleção de features é realizada durante o próprio processo de treinamento do modelo. Certos algoritmos possuem mecanismos internos para ponderar a importância das features.
        * **Técnicas Comuns**:
            * **Regularização L1 (Lasso)**: Modelos como a Regressão Lasso adicionam uma penalidade que força os coeficientes das features menos importantes a se tornarem exatamente zero, efetivamente as removendo do modelo.
            * **Importância de Features em Árvores (Tree-based Importance)**: Modelos como Random Forest e Gradient Boosting calculam naturalmente uma pontuação de importância para cada feature. Pode-se usar essas pontuações para descartar as features menos importantes.
        * **Quando usar**: São um excelente meio-termo entre a performance dos métodos Wrapper e a velocidade dos métodos de Filtro. São altamente eficientes e amplamente utilizados na prática.