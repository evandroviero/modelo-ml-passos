# Roteiro de Estudos de ML – Módulo 2: Modelos de Aprendizado Supervisionado

O Aprendizado Supervisionado é a categoria de Machine Learning onde trabalhamos com dados "rotulados". Isso significa que para cada conjunto de dados de entrada (features, X), já conhecemos o resultado ou a resposta correta (rótulo, y). O objetivo do modelo é aprender a mapear a entrada para a saída, de forma que consiga prever a saída para novos dados de entrada que nunca viu antes. Pense nisso como aprender com um professor ou um gabarito: você estuda os exemplos e suas respectivas respostas para depois ser capaz de responder a novas perguntas sozinho. As duas tarefas mais comuns no Aprendizado Supervisionado são **Regressão** e **Classificação**.

# Regressão: Previsão de Valores Contínuos

**Objetivo**: Prever um valor numérico contínuo. A saída do modelo é uma quantidade, não uma categoria.

Exemplos de Problemas:

* Qual será o preço de um imóvel em um determinado bairro?
* Qual será a temperatura amanhã?
* Quantas unidades de um produto serão vendidas no próximo mês?
* Qual a expectativa de vida de um paciente com base em seu histórico de saúde?

####  Regressão Linear:

* **Descrição**: É o modelo mais simples e fundamental. Tenta encontrar a melhor linha reta (ou plano, em múltiplas dimensões) que descreve a relação entre as variáveis de entrada (X) e a variável de saída (y). A fórmula é $y = \beta_0 + \beta_1 x _1 + \beta_2 x _2 + \epsilon$
* **Ideal para**: Problemas onde a relação entre as variáveis é aproximadamente linear. É um ótimo ponto de partida (baseline).
* **Vantagens**: Rápido, simples de treinar e muito interpretável (os coeficientes β indicam a importância de cada feature).
* **Desvantagens**: Pressupõe uma relação linear entre as variáveis, o que nem sempre é verdade.

#### Árvores de Decisão (Decision Trees):

* **Descrição**: Funciona criando uma estrutura de "árvore" com uma série de regras de "se-então-senão" para chegar a um valor de previsão. Cada nó da árvore representa uma decisão sobre uma feature, e cada folha (nó final) contém o valor numérico previsto.
* **Ideal para**: Capturar relações não-lineares nos dados.
* **Vantagens**: Fáceis de visualizar e entender.
* **Desvantagens**: Propensas a overfitting (memorizam os dados de treino em vez de generalizar) se não forem "podadas" ou limitadas.

#### Random Forest (Florestas Aleatórias):

* **Descrição**: É um modelo de ensemble que treina múltiplas Árvores de Decisão de forma independente e em subconjuntos aleatórios dos dados. A previsão final é a média das previsões de todas as árvores individuais.
* **Ideal para**: Obter alta precisão e robustez.
* **Vantagens**: Reduz drasticamente o overfitting das árvores individuais e geralmente tem um desempenho muito alto.
* **Desvantagens**: Perde a interpretabilidade direta de uma única árvore (torna-se uma "caixa-preta").

#### Gradient Boosting (ex: XGBoost, LightGBM, CatBoost):

* **Descrição**: Outro modelo de ensemble baseado em árvores, mas que funciona de forma sequencial. Ele treina uma primeira árvore, avalia seus erros, e treina a próxima árvore para corrigir esses erros. O processo continua, com cada árvore focando nas deficiências das anteriores.
* **Idealpara**: Situações que exigem altíssima performance. Frequentemente são os modelos vencedores em competições de ML.
* **Vantagens**: Performance de ponta, altíssima precisão.
* **Desvantagens**: Pode ser complexo de ajustar (muitos hiperparâmetros) e sensível a overfitting se não for bem configurado.

## Métricas de Avaliação para Regressão
As métricas de regressão medem o "tamanho do erro" entre os valores previstos pelo modelo e os valores reais.

### Erro Absoluto Médio (MAE - Mean Absolute Error):
* **O que mede:** A média da diferença absoluta entre as previsões e os valores reais.
* **Interpretação:** "Em média, minhas previsões estão erradas em X unidades". É fácil de entender, pois está na mesma unidade da variável alvo.
* **Quando usar**: É aconselhado quando você deseja uma métrica de erro que seja fácil de interpretar e comunicar para stakeholders de negócio, pois ela está na mesma unidade da variável alvo (ex: o erro médio é de R$ 50,00). Use o MAE quando todos os erros, grandes ou pequenos, têm um peso linear. Ou seja, um erro de 20 é exatamente duas vezes pior que um erro de 10. Ele é menos sensível a outliers do que o RMSE.

### Erro Quadrático Médio (MSE - Mean Squared Error):
* **O que mede**: A média do quadrado das diferenças entre previsão e real.
* **Interpretação**: Penaliza erros maiores com muito mais força do que erros pequenos. É útil, mas a unidade fica ao quadrado (ex: R$²), o que dificulta a interpretação direta.
* **Quando usar**: É raramente usado como métrica final de avaliação devido à sua unidade quadrática (difícil de interpretar), mas é fundamental durante o treinamento de muitos modelos (sua derivada matemática é mais fácil de calcular). Aconselha-se pensar no MSE quando erros grandes são desproporcionalmente piores que erros pequenos. Por exemplo, em previsões financeiras, um erro gigantesco pode ser catastrófico, e o MSE irá penalizar o modelo severamente por ele.

### Raiz do Erro Quadrático Médio (RMSE - Root Mean Squared Error):
* **O que mede**: A raiz quadrada do MSE.
* **Interpretação**: Similar ao MSE, penaliza erros grandes, mas tem a vantagem de estar na mesma unidade da variável alvo, como o MAE, tornando-se mais interpretável.
* **Quando usar**: É a métrica mais popular para problemas de regressão. É a escolha ideal quando você quer penalizar erros maiores (como o MSE), mas ainda quer ter uma métrica que seja interpretável e na mesma unidade da variável alvo (como o MAE). Se você não tiver certeza de qual métrica de erro usar, o RMSE é geralmente um ponto de partida seguro e robusto.

### Coeficiente de Determinação (R²):
* **O que mede**: A proporção da variância na variável alvo que é explicada pelo modelo. Varia de 0 a 1 (ou pode ser negativo para modelos muito ruins).
* **Interpretação**: "Um R² de 0.85 significa que o modelo consegue explicar 85% da 'variação' dos dados". Quanto mais perto de 1, melhor o modelo se ajusta aos dados.
* **Quando usar**: É aconselhado quando o objetivo principal não é saber o "tamanho do erro", mas sim entender o quão bem o modelo se ajusta aos dados. Use o R² para comunicar a "força explicativa" do seu modelo. Por exemplo, um R² de 0.90 indica que 90% da variação nos preços dos imóveis é explicada pelas features do seu modelo. É excelente para comparar o ajuste de diferentes modelos no mesmo conjunto de dados.

## Classificação: Previsão de Categorias

**Objetivo**: Prever um rótulo ou uma categoria discreta. A saída do modelo é a qual classe uma nova observação pertence.

Exemplos de Problemas:
* Este e-mail é spam ou não spam? (Classificação Binária)
* Um cliente vai cancelar a assinatura (churn) ou não? (Classificação Binária)
* Qual a espécie desta flor: Iris setosa, Iris virginica ou Iris versicolor? (Classificação Multiclasse)
* Uma imagem contém um cachorro, um gato ou um pássaro? (Classificação Multiclasse)

### Regressão Logística:
* **Descrição**: Apesar do nome, é o modelo de classificação mais fundamental. Ele usa a função logística (sigmoide) para "espremer" a saída de uma equação linear entre 0 e 1, que é interpretada como a probabilidade de a observação pertencer à classe positiva.
* **Ideal para**: Ser um excelente modelo de base (baseline) para problemas de classificação binária.
* **Vantagens**: Rápido, interpretável e fornece probabilidades.
* **Desvantagens**: Pressupõe uma fronteira de decisão linear entre as classes.

### K-Vizinhos Mais Próximos (K-Nearest Neighbors - KNN):
* **Descrição**: Um modelo não-paramétrico e muito intuitivo. Para classificar um novo ponto, ele olha para os 'K' pontos de treino mais próximos a ele e atribui a classe que for majoritária entre esses vizinhos.
* **Ideal para**: Problemas onde a fronteira de decisão é irregular e não-linear.
* **Vantagens**: Simples de entender e implementar.
* **Desvantagens**: Pode ser lento em tempo de previsão (precisa calcular distâncias para todos os pontos) e é sensível à escala das features.

### Support Vector Machines (SVM):
* **Descrição**: O SVM busca encontrar o "hiperplano" (uma linha ou plano) que melhor separa as classes no espaço das features, maximizando a margem (distância) entre as classes e este hiperplano.
* **Ideal para**: Problemas de classificação com muitas features (alta dimensionalidade).
* **Vantagens**: Muito eficaz em espaços de alta dimensão e robusto contra overfitting.
* **Desvantagens**: Pode ser computacionalmente caro e menos interpretável.

Além destes, **Árvores de Decisão**, **Random Forest** e **Gradient Boosting** também são excelentes e amplamente utilizados para tarefas de classificação, com um funcionamento análogo às suas versões de regressão, mas prevendo uma classe em vez de um número.

## Métricas de Avaliação para Classificação

A avaliação de modelos de classificação geralmente começa com a Matriz de Confusão.

### Matriz de Confusão*: 
* **O que mede**: Uma tabela que resume o desempenho do modelo comparando as classes previstas com as classes reais.
    * Verdadeiro Positivo (TP): Real: Positivo, Previsto: Positivo (Acerto)
    * Verdadeiro Negativo (TN): Real: Negativo, Previsto: Negativo (Acerto)
    * Falso Positivo (FP - Erro Tipo I): Real: Negativo, Previsto: Positivo (Alarme Falso)
    * Falso Negativo (FN - Erro Tipo II): Real: Positivo, Previsto: Negativo (Falha)

A partir da matriz, derivamos as seguintes métricas:

### **Acurácia (Accuracy)**:
* **O que mede**: A porcentagem geral de previsões corretas.
* **Fórmula**: (TP+TN)/(TP+TN+FP+FN)
* **Cuidado**: Pode ser uma métrica enganosa em datasets desbalanceados (ex: 99% dos casos são negativos).
* **Quando usar**: Use a acurácia com confiança apenas quando as classes do seu dataset são balanceadas (ex: 50% de e-mails são spam, 50% não são). Em datasets desbalanceados, ela é enganosa. Por exemplo, se 99% dos e-mails não são spam, um modelo que prevê "não spam" para tudo terá 99% de acurácia, mas será inútil.

### Precisão (Precision):
* **O que mede**: Dos que foram classificados como Positivos, quantos eram realmente Positivos?
* **Fórmula**: TP/(TP+FP)
* **Importância**: Alta quando o custo de um Falso Positivo é alto (ex: um filtro de spam que deleta um e-mail importante).
* **Quando usar**: É a métrica mais importante quando o custo de um Falso Positivo é alto.
    * Exemplo de Negócio: Filtro de spam em e-mails. Um Falso Positivo significa que um e-mail importante foi para a lixeira (custo alto). Você quer ter certeza (alta precisão) antes de classificar algo como spam. 
    * Pense: "É melhor deixar passar alguns spams (Falso Negativo) do que perder um e-mail importante (Falso Positivo)".

### Recall (Revocação ou Sensibilidade):
* **O que mede**: De todos os Positivos reais, quantos o modelo conseguiu encontrar?
* **Fórmula**: TP/(TP+FN)
* **Importância**: Alta quando o custo de um Falso Negativo é alto (ex: um diagnóstico médico que falha em detectar uma doença).
* **Quando usar**: É a métrica mais importante quando o custo de um Falso Negativo é alto.  
    * Exemplo de Negócio: Detecção de fraude ou diagnóstico de doenças graves. Um Falso Negativo significa que uma fraude não foi detectada ou uma doença não foi diagnosticada (custo catastrófico). Você quer encontrar todos os casos positivos possíveis, mesmo que isso signifique gerar alguns alarmes falsos (Falsos Positivos).
    * Pense: "É melhor investigar algumas transações legítimas (Falso Positivo) do que deixar uma fraude passar batido (Falso Negativo)".

### F1-Score:
* **O que mede**: A média harmônica entre Precisão e Recall, criando um balanço entre as duas.
* **Fórmula**: 
$$
F_1 = 2 \cdot \frac{precision \cdot recall}{precision + recall}
$$
* **Importância**: Útil quando você precisa de um bom equilíbrio entre Precisão e Recall.
* **Quando usar**: É a melhor escolha quando você precisa de um equilíbrio entre Precisão e Recall. Use o F1-Score quando os custos de Falsos Positivos e Falsos Negativos são ambos importantes e você precisa de uma única métrica para comparar modelos. É a métrica padrão para a maioria dos problemas com classes desbalanceadas.

### AUC (Area Under the Curve) - Curva ROC:
* **O que mede**: A capacidade do modelo de distinguir entre as classes. A Curva ROC plota o Recall (Taxa de Verdadeiros Positivos) vs. a Taxa de Falsos Positivos. A AUC é a área sob essa curva.
* **Interpretação**: Varia de 0.5 (modelo inútil, aleatório) a 1.0 (classificador perfeito). Uma métrica excelente para comparar modelos de forma geral.
* **Quando usar**: É excelente para ter uma visão agregada do desempenho do modelo. Como ela avalia todos os limiares de probabilidade, é uma ótima maneira de comparar diferentes modelos entre si. Uma AUC mais alta significa um modelo melhor em separar as classes. É muito robusta para datasets desbalanceados.